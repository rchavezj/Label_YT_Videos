{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame\n",
      "video\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import subprocess\n",
    "from subprocess import check_output\n",
    "try:\n",
    "    print(check_output([\"ls\", \"../v2\"]).decode(\"utf8\"))\n",
    "except subprocess.CalledProcessError as e:\n",
    "    raise RuntimeError(\"command '{}' return with error (code {}): {}\".format(e.cmd, e.returncode, e.output))\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now, let's read the frame-level data\n",
    "# due to execution time, we're only going to read the first video\n",
    "video_files = os.listdir(\"../v2/video/\")\n",
    "frame_files = os.listdir(\"../v2/frame/\")\n",
    "\n",
    "# Global variables\n",
    "num_labels = 4716"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTargetVec(labels):\n",
    "    out = np.zeros((1, num_labels))\n",
    "    for label in labels:\n",
    "        out[0,label] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(frames, samples=5, k=0):\n",
    "    rgb_input = np.empty((samples, 100, 1024))\n",
    "    audio_input = np.empty((samples, 100, 128))\n",
    "    label_output = np.empty((samples, num_labels))\n",
    "    sess = tf.InteractiveSession()\n",
    "    for example in tf.python_io.tf_record_iterator(frames):        \n",
    "        tf_seq_example = tf.train.SequenceExample.FromString(example)\n",
    "        labels = tf_seq_example.context.feature['labels'].int64_list.value\n",
    "        rgb_frame = np.zeros((100, 1024))\n",
    "        audio_frame = np.zeros((100, 128))\n",
    "        for i in range(100):\n",
    "            rgb_frame[i] = tf.cast(tf.decode_raw(\n",
    "                   tf_seq_example.feature_lists.feature_list['rgb'].feature[i].bytes_list.value[0],tf.uint8)\n",
    "                          ,tf.float32).eval()\n",
    "            audio_frame[i] = tf.cast(tf.decode_raw(\n",
    "                    tf_seq_example.feature_lists.feature_list['audio'].feature[i].bytes_list.value[0],tf.uint8)\n",
    "                           ,tf.float32).eval()\n",
    "        rgb_input[k] = rgb_frame\n",
    "        audio_input[k] = audio_frame\n",
    "        label_output[k] = createTargetVec(labels[:])\n",
    "        k += 1\n",
    "        progress = (k / samples) * 100\n",
    "        if int(progress) % 10 == 0:\n",
    "            print(\"Progress\", progress, \"%\")\n",
    "        if k >= samples:\n",
    "            break\n",
    "    sess.close()\n",
    "    return audio_input, rgb_input, label_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 20.0 %\n",
      "Progress 40.0 %\n",
      "Progress 60.0 %\n",
      "Progress 80.0 %\n",
      "Progress 100.0 %\n"
     ]
    }
   ],
   "source": [
    "# video_lvl_record = \"../v2/video/train-1.tfrecord\"\n",
    "frame_lvl_record = \"../v2/frame/train4f.tfrecord\"\n",
    "\n",
    "audio_input, rgb_input, label_output = get_dataset(frame_lvl_record)\n",
    "\n",
    "X_train_rgb, X_test_rgb, _, _ = train_test_split(rgb_input, label_output, test_size=0.2, random_state=42)\n",
    "X_train_audio, X_test_audio, y_train, y_test = train_test_split(audio_input, label_output, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 train rgb\n",
      "1 test rgb\n",
      "\n",
      "4 train sequences\n",
      "1 test sequences\n",
      "\n",
      "X_train_rgb shape: (4, 100, 1024)\n",
      "X_test_rgb shape: (1, 100, 1024)\n",
      "\n",
      "X_train_audio shape: (4, 100, 128)\n",
      "X_test_audio shape: (1, 100, 128)\n",
      "\n",
      "y_train shape: (4, 4716)\n",
      "y_test shape: (1, 4716)\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_rgb), 'train rgb')\n",
    "print(len(X_test_rgb), 'test rgb')\n",
    "print(\"\")\n",
    "print(len(X_train_audio), 'train sequences')\n",
    "print(len(X_test_audio), 'test sequences')\n",
    "print(\"\")\n",
    "print('X_train_rgb shape:', X_train_rgb.shape)\n",
    "print('X_test_rgb shape:', X_test_rgb.shape)\n",
    "print(\"\")\n",
    "print('X_train_audio shape:', X_train_audio.shape)\n",
    "print('X_test_audio shape:', X_test_audio.shape)\n",
    "print(\"\")\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [X_train_rgb, X_train_audio]\n",
    "X_test = [X_test_rgb, X_test_audio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "# 4\n",
    "# 100\n",
    "# 1024\n",
    "len(X_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets take a look at the rgb data\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 100, 1024)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100.,  54.,  84., ...,  46.,  10., 132.],\n",
       "       [105.,   0.,  91., ..., 153.,  27., 103.],\n",
       "       [ 93.,  24.,  95., ...,  84., 113., 130.],\n",
       "       ...,\n",
       "       [ 90.,  35., 122., ..., 190., 155., 147.],\n",
       "       [ 86.,  26., 112., ..., 129., 100., 126.],\n",
       "       [ 81.,  12., 120., ..., 222., 114., 140.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1024)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_input[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first video has 100 frames\n"
     ]
    }
   ],
   "source": [
    "print('The first video has %d frames' %len(rgb_input[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.,  54.,  84., ...,  46.,  10., 132.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_input[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_input[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_data = np.array( [np.array(cv2.imread(rgb_input[0][0])) for i in range(len(rgb_input[0][0]))] )\n",
    "# print (x_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now were ready to create our model\n",
    "****\n",
    "** Since we're given sequential data, most likely I'll use an LSTM or GRU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.merge import dot, concatenate\n",
    "from keras.layers import LSTM, Input, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# audio_frame\n",
    "X1 = Input(shape=(128,),name='audio_frame')\n",
    "dense_1 = Dense(2048, activation='relu',name='dense_1')(X1)\n",
    "batchNormalization_1 = BatchNormalization(name='batchNormalization_1')(dense_1)\n",
    "leakyrelu_1 = LeakyReLU(alpha=.001, name='leakyrelu_1')(batchNormalization_1)\n",
    "dropout_1 = Dropout(0.2, name='dropout_1')(leakyrelu_1)\n",
    "dense_2 = Dense(2048, activation='relu',name='dense_2')(dropout_1)\n",
    "batchNormalization_2 = BatchNormalization(name='batchNormalization_2')(dense_2)\n",
    "leakyrelu_2 = LeakyReLU(alpha=.001, name='leakyrelu_2')(batchNormalization_2)\n",
    "dropout_2 = Dropout(0.2, name='dropout_2')(leakyrelu_2)\n",
    "dense_3 = Dense(2048, activation='relu',name='dense_3')(dropout_2)\n",
    "# First Merge\n",
    "merge_1 = keras.layers.Add(name='merge_1')([dense_3, dropout_1])\n",
    "leakyrelu_3 = LeakyReLU(alpha=.001, name='leakyrelu_3')(merge_1)\n",
    "\n",
    "# Complete Model Diagram\n",
    "audio_frame_model = Model(inputs=[X1],outputs=[leakyrelu_3])\n",
    "plot_model(audio_frame_model,to_file='audio_frame_model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rgb_frame\n",
    "X2 = Input(shape=(1024,),name='rgb_frame')\n",
    "dense_4 = Dense(2048, activation='relu',name='dense_4')(X2)\n",
    "batchNormalization_3 = BatchNormalization(name='batchNormalization_3')(dense_4)\n",
    "leakyrelu_4 = LeakyReLU(alpha=.001, name='leakyrelu_4')(batchNormalization_3)\n",
    "dropout_3 = Dropout(0.2, name='dropout_3')(leakyrelu_4)\n",
    "dense_5 = Dense(2048, activation='relu',name='dense_5')(dropout_3)\n",
    "batchNormalization_4 = BatchNormalization(name='batchNormalization_4')(dense_5)\n",
    "leakyrelu_5 = LeakyReLU(alpha=.001, name='leakyrelu_5')(batchNormalization_4)\n",
    "dropout_4 = Dropout(0.2, name='dropout_4')(leakyrelu_5)\n",
    "dense_6 = Dense(2048, activation='relu',name='dense_6')(dropout_4)\n",
    "# Merging time\n",
    "merge_2 = keras.layers.Add(name='merge_2')([dense_6, dropout_3])\n",
    "leakyrelu_6 = LeakyReLU(alpha=.001, name='leakyrelu_6')(merge_2)\n",
    "\n",
    "# Complete Model Diagram\n",
    "rgb_frame_model = Model(inputs=[X2],outputs=[leakyrelu_6])\n",
    "plot_model(rgb_frame_model,to_file='rgb_frame_model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Complete Model Diagram\n",
    "# First merge between audio and rgb features\n",
    "merge_audio_rgb = concatenate([leakyrelu_3, leakyrelu_6], name='merge_audio_rgb')\n",
    "audio_rgb_model = Model(inputs=[X1,X2],outputs=[merge_audio_rgb])\n",
    "plot_model(audio_rgb_model,to_file='audio_rgb_model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dense_7 = Dense(2048, activation='relu',name='dense_7')(merge_audio_rgb)\n",
    "batchNormalization_5 = BatchNormalization(name='batchNormalization_5')(dense_7)\n",
    "leakyrelu_7 = LeakyReLU(alpha=.001, name='leakyrelu_7')(batchNormalization_5)\n",
    "dropout_5 = Dropout(0.2, name='dropout_5')(leakyrelu_7)\n",
    "dense_8 = Dense(4096, activation='relu',name='dense_8')(dropout_5)\n",
    "\n",
    "# _model = Model(inputs=[merge_audio_rgb],outputs=[dense_8])\n",
    "# plot_model(_model,to_file='_model.png',show_shapes=True)\n",
    "# Merging time\n",
    "merge_3 = keras.layers.Add(name='merge_3')([dense_8, merge_audio_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leakyrelu_8 = LeakyReLU(alpha=.001, name='leakyrelu_8')(merge_3)\n",
    "dense_9 = Dense(2048, activation='relu',name='dense_9')(dropout_5)\n",
    "batchNormalization_6 = BatchNormalization(name='batchNormalization_6')(dense_9)\n",
    "leakyrelu_9 = LeakyReLU(alpha=.001, name='leakyrelu_9')(batchNormalization_6)\n",
    "dropout_6 = Dropout(0.2, name='dropout_6')(leakyrelu_9)\n",
    "dense_10 = Dense(4716, activation='relu',name='dense_10')(dropout_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete Model Diagram\n",
    "finalOutput = Model(inputs=[X1,X2],outputs=[dense_10])\n",
    "plot_model(finalOutput,to_file='finalOutput.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalOutput.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "audio_frame (InputLayer)        (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rgb_frame (InputLayer)          (None, 1024)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2048)         264192      audio_frame[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2048)         2099200     rgb_frame[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batchNormalization_1 (BatchNorm (None, 2048)         8192        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batchNormalization_3 (BatchNorm (None, 2048)         8192        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leakyrelu_1 (LeakyReLU)         (None, 2048)         0           batchNormalization_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leakyrelu_4 (LeakyReLU)         (None, 2048)         0           batchNormalization_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           leakyrelu_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 2048)         0           leakyrelu_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2048)         4196352     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2048)         4196352     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batchNormalization_2 (BatchNorm (None, 2048)         8192        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batchNormalization_4 (BatchNorm (None, 2048)         8192        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leakyrelu_2 (LeakyReLU)         (None, 2048)         0           batchNormalization_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leakyrelu_5 (LeakyReLU)         (None, 2048)         0           batchNormalization_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           leakyrelu_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 2048)         0           leakyrelu_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2048)         4196352     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2048)         4196352     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Add)                   (None, 2048)         0           dense_3[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_2 (Add)                   (None, 2048)         0           dense_6[0][0]                    \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leakyrelu_3 (LeakyReLU)         (None, 2048)         0           merge_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leakyrelu_6 (LeakyReLU)         (None, 2048)         0           merge_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_audio_rgb (Concatenate)   (None, 4096)         0           leakyrelu_3[0][0]                \n",
      "                                                                 leakyrelu_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2048)         8390656     merge_audio_rgb[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batchNormalization_5 (BatchNorm (None, 2048)         8192        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leakyrelu_7 (LeakyReLU)         (None, 2048)         0           batchNormalization_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 2048)         0           leakyrelu_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 2048)         4196352     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batchNormalization_6 (BatchNorm (None, 2048)         8192        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leakyrelu_9 (LeakyReLU)         (None, 2048)         0           batchNormalization_6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 2048)         0           leakyrelu_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 4716)         9663084     dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 41,448,044\n",
      "Trainable params: 41,423,468\n",
      "Non-trainable params: 24,576\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(finalOutput.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected audio_frame to have 2 dimensions, but got array with shape (4, 100, 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-3dd18ac18ef3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinalOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_rgb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test_audio\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected audio_frame to have 2 dimensions, but got array with shape (4, 100, 128)"
     ]
    }
   ],
   "source": [
    "finalOutput.fit([X_train_audio, X_train_rgb], y_train, validation_data=([X_test_audio], y_test), epochs=60, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
