{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame\n",
      "video\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import subprocess\n",
    "from subprocess import check_output\n",
    "try:\n",
    "    print(check_output([\"ls\", \"../v2\"]).decode(\"utf8\"))\n",
    "except subprocess.CalledProcessError as e:\n",
    "    raise RuntimeError(\"command '{}' return with error (code {}): {}\".format(e.cmd, e.returncode, e.output))\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now, let's read the frame-level data\n",
    "# due to execution time, we're only going to read the first video\n",
    "video_files = os.listdir(\"../v2/video/\")\n",
    "frame_files = os.listdir(\"../v2/frame/\")\n",
    "\n",
    "# Global variables\n",
    "num_labels = 4716"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTargetVec(labels):\n",
    "    out = np.zeros((1, num_labels))\n",
    "    for label in labels:\n",
    "        out[0,label] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(frames, samples=5, k=0):\n",
    "    rgb_input = np.empty((samples, 100, 1024))\n",
    "    audio_input = np.empty((samples, 100, 128))\n",
    "    label_output = np.empty((samples, num_labels))\n",
    "    sess = tf.InteractiveSession()\n",
    "    for example in tf.python_io.tf_record_iterator(frames):        \n",
    "        tf_seq_example = tf.train.SequenceExample.FromString(example)\n",
    "        labels = tf_seq_example.context.feature['labels'].int64_list.value\n",
    "        rgb_frame = np.zeros((100, 1024))\n",
    "        audio_frame = np.zeros((100, 128))\n",
    "        for i in range(100):\n",
    "            rgb_frame[i] = tf.cast(tf.decode_raw(\n",
    "                   tf_seq_example.feature_lists.feature_list['rgb'].feature[i].bytes_list.value[0],tf.uint8)\n",
    "                          ,tf.float32).eval()\n",
    "            audio_frame[i] = tf.cast(tf.decode_raw(\n",
    "                    tf_seq_example.feature_lists.feature_list['audio'].feature[i].bytes_list.value[0],tf.uint8)\n",
    "                           ,tf.float32).eval()\n",
    "#         print(\"rgb_frame: \", rgb_frame)\n",
    "        rgb_input[k] = rgb_frame\n",
    "#         print(\"rgb_input: \", rgb_input)\n",
    "        audio_input[k] = audio_frame\n",
    "        label_output[k] = createTargetVec(labels[:])\n",
    "        k += 1\n",
    "        progress = (k / samples) * 100\n",
    "        if int(progress) % 10 == 0:\n",
    "            print(\"Progress\", progress, \"%\")\n",
    "        if k >= samples:\n",
    "            break\n",
    "    sess.close()\n",
    "    return audio_input, rgb_input, label_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 20.0 %\n",
      "Progress 40.0 %\n",
      "Progress 60.0 %\n",
      "Progress 80.0 %\n",
      "Progress 100.0 %\n"
     ]
    }
   ],
   "source": [
    "frame_lvl_record = \"../v2/frame/train4f.tfrecord\"\n",
    "\n",
    "audio_input, rgb_input, label_output = get_dataset(frame_lvl_record)\n",
    "\n",
    "X_train_rgb, X_test_rgb, _, _ = train_test_split(rgb_input, label_output, test_size=0.2, random_state=42)\n",
    "X_train_audio, X_test_audio, y_train, y_test = train_test_split(audio_input, label_output, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0.,  72., 173., ..., 142., 119., 137.],\n",
       "        [  0.,  72., 173., ..., 142., 119., 137.],\n",
       "        [  0.,  72., 173., ..., 142., 119., 137.],\n",
       "        ...,\n",
       "        [229., 153., 194., ..., 103., 120., 188.],\n",
       "        [165., 165., 228., ..., 140., 101., 214.],\n",
       "        [226., 151., 219., ..., 124.,  91.,  88.]],\n",
       "\n",
       "       [[  0.,  85., 148., ..., 124., 135., 133.],\n",
       "        [  0.,  62., 104., ..., 116., 111., 128.],\n",
       "        [  0.,  75., 103., ...,  74.,  26., 176.],\n",
       "        ...,\n",
       "        [144., 172.,  86., ..., 244.,  72.,  95.],\n",
       "        [210., 153., 100., ..., 255., 200., 189.],\n",
       "        [200., 160.,  99., ..., 194., 220., 195.]],\n",
       "\n",
       "       [[100.,  54.,  84., ...,  46.,  10., 132.],\n",
       "        [105.,   0.,  91., ..., 153.,  27., 103.],\n",
       "        [ 93.,  24.,  95., ...,  84., 113., 130.],\n",
       "        ...,\n",
       "        [ 90.,  35., 122., ..., 190., 155., 147.],\n",
       "        [ 86.,  26., 112., ..., 129., 100., 126.],\n",
       "        [ 81.,  12., 120., ..., 222., 114., 140.]],\n",
       "\n",
       "       [[161.,  57.,  93., ...,  44., 179.,  85.],\n",
       "        [185.,  51., 105., ...,  82., 226.,   0.],\n",
       "        [181.,  41., 130., ..., 107., 231.,  42.],\n",
       "        ...,\n",
       "        [141., 164., 108., ..., 139.,  56.,  73.],\n",
       "        [128., 132., 100., ..., 110., 112., 132.],\n",
       "        [110., 155.,  86., ..., 102., 143., 138.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 100, 1024)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[173.,  27., 126., ..., 133., 130., 187.],\n",
       "        [173.,  27., 126., ..., 133., 130., 187.],\n",
       "        [182.,  67.,  94., ..., 133.,  82., 137.],\n",
       "        ...,\n",
       "        [216.,  99., 127., ...,  83., 184., 154.],\n",
       "        [203.,  91., 135., ..., 101.,  76.,  75.],\n",
       "        [197., 139., 162., ..., 189., 185., 122.]],\n",
       "\n",
       "       [[173.,  27., 126., ..., 133., 130., 187.],\n",
       "        [165.,  94., 111., ...,  57., 155., 255.],\n",
       "        [164.,  96.,  89., ..., 199., 176., 154.],\n",
       "        ...,\n",
       "        [182., 109.,  92., ..., 175., 255.,   0.],\n",
       "        [188., 108., 106., ..., 118., 192.,   0.],\n",
       "        [188., 127., 100., ..., 160.,  24.,   0.]],\n",
       "\n",
       "       [[148., 104., 159., ..., 247.,  62., 149.],\n",
       "        [120.,  83., 186., ..., 182.,  61., 180.],\n",
       "        [118.,  75., 117., ..., 195.,  85.,  59.],\n",
       "        ...,\n",
       "        [ 43., 210.,   5., ...,  55., 252., 236.],\n",
       "        [118.,  75., 133., ..., 159.,   0., 240.],\n",
       "        [ 33., 218.,   8., ...,  15., 255., 221.]],\n",
       "\n",
       "       [[102.,  87., 123., ...,  57., 155., 142.],\n",
       "        [ 80.,  71., 118., ..., 255., 160.,  88.],\n",
       "        [ 72.,  80., 127., ..., 255., 248., 167.],\n",
       "        ...,\n",
       "        [ 69., 153., 142., ...,  38.,   7., 174.],\n",
       "        [ 62., 196.,  28., ..., 138., 255.,   1.],\n",
       "        [ 76., 182.,  38., ...,  41., 176., 171.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 100, 128)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rgb: 1024\n",
    "# audio: 128\n",
    "x_train_np = np.concatenate((X_train_rgb, X_train_audio), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 100, 1152)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test_np = np.concatenate((X_test_rgb, X_test_audio), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100, 1152)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_rgb_ = np.split(x_train_np, [128], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 100, 128)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_rgb_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 train rgb\n",
      "1 test rgb\n",
      "\n",
      "4 train sequences\n",
      "1 test sequences\n",
      "\n",
      "X_train_rgb shape: (4, 100, 1024)\n",
      "X_test_rgb shape: (1, 100, 1024)\n",
      "\n",
      "X_train_audio shape: (4, 100, 128)\n",
      "X_test_audio shape: (1, 100, 128)\n",
      "\n",
      "y_train shape: (4, 4716)\n",
      "y_test shape: (1, 4716)\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_rgb), 'train rgb')\n",
    "print(len(X_test_rgb), 'test rgb')\n",
    "print(\"\")\n",
    "print(len(X_train_audio), 'train sequences')\n",
    "print(len(X_test_audio), 'test sequences')\n",
    "print(\"\")\n",
    "print('X_train_rgb shape:', X_train_rgb.shape)\n",
    "print('X_test_rgb shape:', X_test_rgb.shape)\n",
    "print(\"\")\n",
    "print('X_train_audio shape:', X_train_audio.shape)\n",
    "print('X_test_audio shape:', X_test_audio.shape)\n",
    "print(\"\")\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [X_train_rgb, X_train_audio]\n",
    "X_test = [X_test_rgb, X_test_audio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "# 4\n",
    "# 100\n",
    "# 1024\n",
    "len(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0.,  72., 173., ..., 142., 119., 137.],\n",
       "        [  0.,  72., 173., ..., 142., 119., 137.],\n",
       "        [  0.,  72., 173., ..., 142., 119., 137.],\n",
       "        ...,\n",
       "        [229., 153., 194., ..., 103., 120., 188.],\n",
       "        [165., 165., 228., ..., 140., 101., 214.],\n",
       "        [226., 151., 219., ..., 124.,  91.,  88.]],\n",
       "\n",
       "       [[  0.,  85., 148., ..., 124., 135., 133.],\n",
       "        [  0.,  62., 104., ..., 116., 111., 128.],\n",
       "        [  0.,  75., 103., ...,  74.,  26., 176.],\n",
       "        ...,\n",
       "        [144., 172.,  86., ..., 244.,  72.,  95.],\n",
       "        [210., 153., 100., ..., 255., 200., 189.],\n",
       "        [200., 160.,  99., ..., 194., 220., 195.]],\n",
       "\n",
       "       [[100.,  54.,  84., ...,  46.,  10., 132.],\n",
       "        [105.,   0.,  91., ..., 153.,  27., 103.],\n",
       "        [ 93.,  24.,  95., ...,  84., 113., 130.],\n",
       "        ...,\n",
       "        [ 90.,  35., 122., ..., 190., 155., 147.],\n",
       "        [ 86.,  26., 112., ..., 129., 100., 126.],\n",
       "        [ 81.,  12., 120., ..., 222., 114., 140.]],\n",
       "\n",
       "       [[161.,  57.,  93., ...,  44., 179.,  85.],\n",
       "        [185.,  51., 105., ...,  82., 226.,   0.],\n",
       "        [181.,  41., 130., ..., 107., 231.,  42.],\n",
       "        ...,\n",
       "        [141., 164., 108., ..., 139.,  56.,  73.],\n",
       "        [128., 132., 100., ..., 110., 112., 132.],\n",
       "        [110., 155.,  86., ..., 102., 143., 138.]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets take a look at the rgb data\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 100, 1024)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100.,  54.,  84., ...,  46.,  10., 132.],\n",
       "       [105.,   0.,  91., ..., 153.,  27., 103.],\n",
       "       [ 93.,  24.,  95., ...,  84., 113., 130.],\n",
       "       ...,\n",
       "       [ 90.,  35., 122., ..., 190., 155., 147.],\n",
       "       [ 86.,  26., 112., ..., 129., 100., 126.],\n",
       "       [ 81.,  12., 120., ..., 222., 114., 140.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1024)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_input[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first video has 100 frames\n"
     ]
    }
   ],
   "source": [
    "print('The first video has %d frames' %len(rgb_input[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.,  54.,  84., ...,  46.,  10., 132.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_input[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_input[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_data = np.array( [np.array(cv2.imread(rgb_input[0][0])) for i in range(len(rgb_input[0][0]))] )\n",
    "# print (x_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now were ready to create our model\n",
    "****\n",
    "** Since we're given sequential data, most likely I'll use an LSTM or GRU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.merge import dot, concatenate\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Frame\n",
    "*** ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# audio_frame\n",
    "X1 = Input(shape=(100,128),name='audio_frame')\n",
    "dense_1 = Dense(2048,activation='relu',name='dense_1')(X1)\n",
    "batchNormalization_1 = BatchNormalization(name='batchNormalization_1')(dense_1)\n",
    "leakyrelu_1 = LeakyReLU(alpha=.001, name='leakyrelu_1')(batchNormalization_1)\n",
    "dropout_1 = Dropout(0.2, name='dropout_1')(leakyrelu_1)\n",
    "dense_2 = Dense(2048, activation='relu',name='dense_2')(dropout_1)\n",
    "batchNormalization_2 = BatchNormalization(name='batchNormalization_2')(dense_2)\n",
    "leakyrelu_2 = LeakyReLU(alpha=.001, name='leakyrelu_2')(batchNormalization_2)\n",
    "dropout_2 = Dropout(0.2, name='dropout_2')(leakyrelu_2)\n",
    "dense_3 = Dense(2048, activation='relu',name='dense_3')(dropout_2)\n",
    "# First Merge\n",
    "merge_1 = keras.layers.Add(name='merge_1')([dense_3, dropout_1])\n",
    "leakyrelu_3 = LeakyReLU(alpha=.001, name='leakyrelu_3')(merge_1)\n",
    "# Complete Model Diagram\n",
    "audio_frame_model = Model(inputs=[X1],outputs=[leakyrelu_3])\n",
    "plot_model(audio_frame_model,to_file='audio_frame_model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB Frame\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rgb_frame\n",
    "X2 = Input(shape=(100,1024),name='rgb_frame')\n",
    "dense_4 = Dense((2048), activation='relu',name='dense_4')(X2)\n",
    "batchNormalization_3 = BatchNormalization(name='batchNormalization_3')(dense_4)\n",
    "leakyrelu_4 = LeakyReLU(alpha=.001, name='leakyrelu_4')(batchNormalization_3)\n",
    "dropout_3 = Dropout(0.2, name='dropout_3')(leakyrelu_4)\n",
    "dense_5 = Dense(2048, activation='relu',name='dense_5')(dropout_3)\n",
    "batchNormalization_4 = BatchNormalization(name='batchNormalization_4')(dense_5)\n",
    "leakyrelu_5 = LeakyReLU(alpha=.001, name='leakyrelu_5')(batchNormalization_4)\n",
    "dropout_4 = Dropout(0.2, name='dropout_4')(leakyrelu_5)\n",
    "dense_6 = Dense(2048, activation='relu',name='dense_6')(dropout_4)\n",
    "# Merging time\n",
    "merge_2 = keras.layers.Add(name='merge_2')([dense_6, dropout_3])\n",
    "leakyrelu_6 = LeakyReLU(alpha=.001, name='leakyrelu_6')(merge_2)\n",
    "\n",
    "# Complete Model Diagram\n",
    "rgb_frame_model = Model(inputs=[X2],outputs=[leakyrelu_6])\n",
    "plot_model(rgb_frame_model,to_file='rgb_frame_model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge both frames (Audio and RGB)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Complete Model Diagram\n",
    "# First merge between audio and rgb features\n",
    "merge_audio_rgb = concatenate([leakyrelu_3, leakyrelu_6], name='merge_audio_rgb')\n",
    "audio_rgb_model = Model(inputs=[X1,X2],outputs=[merge_audio_rgb])\n",
    "plot_model(audio_rgb_model,to_file='audio_rgb_model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last connections before LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dense_7 = Dense(2048, activation='relu',name='dense_7')(merge_audio_rgb)\n",
    "batchNormalization_5 = BatchNormalization(name='batchNormalization_5')(dense_7)\n",
    "leakyrelu_7 = LeakyReLU(alpha=.001, name='leakyrelu_7')(batchNormalization_5)\n",
    "dropout_5 = Dropout(0.2, name='dropout_5')(leakyrelu_7)\n",
    "dense_8 = Dense(4096, activation='relu',name='dense_8')(dropout_5)\n",
    "\n",
    "# _model = Model(inputs=[merge_audio_rgb],outputs=[dense_8])\n",
    "# plot_model(_model,to_file='_model.png',show_shapes=True)\n",
    "# Merging time\n",
    "merge_3 = keras.layers.Add(name='merge_3')([dense_8, merge_audio_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "leakyrelu_8 = LeakyReLU(alpha=.001, name='leakyrelu_8')(merge_3)\n",
    "dense_9 = Dense(2048, activation='relu',name='dense_9')(leakyrelu_8)\n",
    "batchNormalization_6 = BatchNormalization(name='batchNormalization_6')(dense_9)\n",
    "leakyrelu_9 = LeakyReLU(alpha=.001, name='leakyrelu_9')(batchNormalization_6)\n",
    "dropout_6 = Dropout(0.2, name='dropout_6')(leakyrelu_9)\n",
    "LSTM_ = LSTM(4716, return_sequences=False)(dropout_6)\n",
    "dense_10 = Dense(4716, activation='relu',name='dense_10')(LSTM_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Complete Model Diagram\n",
    "finalOutput = Model(inputs=[X1,X2],outputs=[dense_10])\n",
    "plot_model(finalOutput,to_file='finalOutput.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalOutput.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "audio_frame (InputLayer)        (None, 100, 128)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rgb_frame (InputLayer)          (None, 100, 1024)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100, 2048)    264192      audio_frame[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 100, 2048)    2099200     rgb_frame[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batchNormalization_1 (BatchNorm (None, 100, 2048)    8192        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batchNormalization_3 (BatchNorm (None, 100, 2048)    8192        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leakyrelu_1 (LeakyReLU)         (None, 100, 2048)    0           batchNormalization_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leakyrelu_4 (LeakyReLU)         (None, 100, 2048)    0           batchNormalization_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100, 2048)    0           leakyrelu_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 100, 2048)    0           leakyrelu_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100, 2048)    4196352     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 100, 2048)    4196352     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batchNormalization_2 (BatchNorm (None, 100, 2048)    8192        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batchNormalization_4 (BatchNorm (None, 100, 2048)    8192        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leakyrelu_2 (LeakyReLU)         (None, 100, 2048)    0           batchNormalization_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leakyrelu_5 (LeakyReLU)         (None, 100, 2048)    0           batchNormalization_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100, 2048)    0           leakyrelu_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 100, 2048)    0           leakyrelu_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100, 2048)    4196352     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 100, 2048)    4196352     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Add)                   (None, 100, 2048)    0           dense_3[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_2 (Add)                   (None, 100, 2048)    0           dense_6[0][0]                    \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leakyrelu_3 (LeakyReLU)         (None, 100, 2048)    0           merge_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leakyrelu_6 (LeakyReLU)         (None, 100, 2048)    0           merge_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_audio_rgb (Concatenate)   (None, 100, 4096)    0           leakyrelu_3[0][0]                \n",
      "                                                                 leakyrelu_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 100, 2048)    8390656     merge_audio_rgb[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batchNormalization_5 (BatchNorm (None, 100, 2048)    8192        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leakyrelu_7 (LeakyReLU)         (None, 100, 2048)    0           batchNormalization_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 100, 2048)    0           leakyrelu_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 100, 4096)    8392704     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_3 (Add)                   (None, 100, 4096)    0           dense_8[0][0]                    \n",
      "                                                                 merge_audio_rgb[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leakyrelu_8 (LeakyReLU)         (None, 100, 4096)    0           merge_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 100, 2048)    8390656     leakyrelu_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batchNormalization_6 (BatchNorm (None, 100, 2048)    8192        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leakyrelu_9 (LeakyReLU)         (None, 100, 2048)    0           batchNormalization_6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 100, 2048)    0           leakyrelu_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 4716)         127614960   dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 4716)         22245372    lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 194,232,300\n",
      "Trainable params: 194,207,724\n",
      "Non-trainable params: 24,576\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(finalOutput.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_data=({'audio_frame': X_test_audio,\n",
    "                  'rgb_frame':X_test_rgb}, \n",
    "                 {'dense_10': y_test})\n",
    "\n",
    "training_data = ({'audio_frame': X_train_audio,\n",
    "                  'rgb_frame':X_train_rgb},\n",
    "                 {'dense_10': y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 85s 21s/step - loss: 36.7115 - acc: 0.0000e+00 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 62s 16s/step - loss: 28.1468 - acc: 0.2500 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 58s 15s/step - loss: 23.1987 - acc: 0.2500 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 61s 15s/step - loss: 22.8005 - acc: 0.2500 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 64s 16s/step - loss: 22.6661 - acc: 0.2500 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 65s 16s/step - loss: 22.6000 - acc: 0.2500 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 64s 16s/step - loss: 22.5359 - acc: 0.2500 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 51s 13s/step - loss: 22.5009 - acc: 0.5000 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 50s 13s/step - loss: 22.4545 - acc: 0.5000 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 50s 12s/step - loss: 22.4234 - acc: 0.5000 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 49s 12s/step - loss: 22.4031 - acc: 0.5000 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 50s 13s/step - loss: 22.3832 - acc: 0.5000 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 51s 13s/step - loss: 22.3700 - acc: 0.5000 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 51s 13s/step - loss: 22.3652 - acc: 0.5000 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 50s 12s/step - loss: 22.3445 - acc: 0.5000 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 54s 13s/step - loss: 22.3424 - acc: 0.5000 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 50s 12s/step - loss: 22.4153 - acc: 0.5000 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 50s 13s/step - loss: 22.3237 - acc: 0.5000 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 51s 13s/step - loss: 22.3208 - acc: 0.5000 - val_loss: 64.4724 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 50s 13s/step - loss: 22.3169 - acc: 0.5000 - val_loss: 64.4724 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a17d686d8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalOutput.fit([X_train_audio, X_train_rgb], y_train, validation_data=([X_test_audio, X_test_rgb], y_test), epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finalOutput.save_weights(\"finalOutput.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 99.85%\n"
     ]
    }
   ],
   "source": [
    "# evaluate loaded model on test data\n",
    "finalOutput.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "_score = finalOutput.evaluate([X_train_audio, X_train_rgb], y_train, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (finalOutput.metrics_names[1], _score[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
